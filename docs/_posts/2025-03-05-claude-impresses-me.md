---
title: "Claude 3.7 Impresses Me"
date: 2025-03-05
tags: 
    - AI
    - LLM
    - Machine Learning
    - Technology
    - Programming
    - Productivity
---

I'm writing this post because it seems as though a large language model (LLM) has hit a milestone that impresses me. Claude 3.7 wrote a nontrivial app based on a prompt I provided that 'just worked.' Throughout the conversation, it was able to make modifications as I suggested and even correct its own coding errors. I've been using these models since early 2024, and they have been a good check on the immense hype surrounding AI.

I remain skeptical about the most fantastic claims, such as achieving the holy grail of artificial intelligence within the next year or even five. The algorithms we have might not be sufficient to get us there, even with significant scaling. There's a lot of momentum and funding behind AI right now, which will help the cause unless a failure to reach these goals leads to a new AI winter and abandonment of hope for the entire enterprise.

I haven't seen sufficient evidence or had adequate explanations from a 'how it works' perspective to become a hardcore believer that we are on the verge of achieving these goals. Recent efforts to use reinforcement learning on top of self-supervised transformers are impressive, but I'm unsure where I stand on reaching that ultimate goal. Solving some of our hardest problems in an accelerated way sounds incredible, but concerns about alignment problems give me pause.

That tangent aside, I do find LLMs to be extraordinary and very impressive for what they are. This post is a celebration of that. What I'm about to share isn't a developer job-killer, but it is impressive.

I've been interested in learning about learning for a while and wanted an app to help with that. Normally, I try to ad-hoc these things, but I asked Claude 3.7 to build me an app, and it did! The app worked inline in the Anthropic console window and was easy to spin off into a React application. It was only front-end, but with more conversations with Claude, I got suggestions to persist data to local storage or a local database. The app provides a schedule, checkboxes, and logic for spaced repetition. While it might not have taken me long to write the core functionality, populating the initial list with data and aesthetics would have taken much longer. Claude did it in less than 2 minutes for the first iteration, with successive prompts totaling less than 8 minutes.

Here is a link to the public repository in case you would like to see what it built for me. It is usable for your own purposes, and Claude built in ways to add and expand on the app.
